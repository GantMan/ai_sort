<!DOCTYPE html>
<html>
  <head>
    <link rel="stylesheet" href="mystyle.css" />
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@2.7.0/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/danfojs@0.1.2/dist/index.min.js"></script>
    <script>
      function enableStep(stepId) {
        document.getElementById('load').disabled = true
        document.getElementById('feature').disabled = true
        document.getElementById('transfer').disabled = true
        document.getElementById('train').disabled = true
        document.getElementById(stepId).disabled = false
      }

      async function loadLabeled() {
        /* --------------------------------/
         * 1. Load new labeled data
         *--------------------------------*/
        const dfy = await dfd.read_csv('labels.csv')
        const dfx = await dfd.read_csv('images.csv')

        const Y = dfy.tensor
        const X = dfx.tensor.reshape([dfx.shape[0], 28, 28, 1])

        window.X = X
        window.Y = Y
        console.log('Y is ready ', Y.shape)
        console.log('X is ready ', X.shape)
        enableStep('feature')
      }

      async function createFeature() {
        /* ---------------------------------------------/
         * 2. Load original model and create features
         *---------------------------------------------*/
        const model = await tf.loadLayersModel('../sorting_hat/model.json')
        model.summary()
        // Gonna shave off
        const layer = model.getLayer('max_pooling2d_MaxPooling2D3')
        const shaved = tf.model({ inputs: model.inputs, outputs: layer.output })
        shaved.summary()
        // Run data through shaved model to get features
        const XFEATURES = shaved.predict(window.X)
        console.log('Images have been featurized')
        console.log('XFEATURES', XFEATURES.shape)

        window.shaved = shaved
        window.XFEATURES = XFEATURES
        window.X.dispose()
        enableStep('transfer')
      }

      async function createTransfer() {
        /* ---------------------------------------------/
         * 3. Create a new model that trains on features
         *---------------------------------------------*/
        transferModel = tf.sequential({
          layers: [
            tf.layers.flatten({
              inputShape: window.shaved.outputs[0].shape.slice(1),
            }),
            tf.layers.dense({ units: 128, activation: 'relu' }),
            tf.layers.dense({ units: 3, activation: 'softmax' }),
          ],
        })
        transferModel.compile({
          optimizer: 'adam',
          loss: 'categoricalCrossentropy',
          metrics: ['accuracy'],
        })
        transferModel.summary()

        window.transferModel = transferModel
        enableStep('train')
      }

      async function train() {
        /* ---------------------------------------------/
         * 4. Transfer learn!
         *---------------------------------------------*/
        await window.transferModel.fit(window.XFEATURES, Y, {
          epochs: 10,
          shuffle: true,
          validationSplit: 0.1,
          callbacks: {
            onEpochEnd: console.log,
          },
        })

        window.XFEATURES.dispose()
        enableStep('clear')
        enableCanvas()
      }

      function displayResults(predictions) {
        document.getElementById('ferengi').style.opacity = predictions[0]
        document.getElementById('klingon').style.opacity = predictions[1]
        document.getElementById('starfleet').style.opacity = predictions[2]
      }

      async function makePrediction(canvas) {
        const drawTensor = tf.browser.fromPixels(canvas, 1)
        const resize = tf.image.resizeNearestNeighbor(
          drawTensor,
          [28, 28],
          true
        )

        const batched = resize.expandDims()
        const resultFeatures = await window.shaved.predict(batched)
        const results = await window.transferModel.predict(resultFeatures)
        const predictions = await results.array()

        // Display
        displayResults(predictions[0])
        // Cleanup
        tf.dispose([drawTensor, resize, batched, results, resultFeatures])
      }

      async function enableCanvas() {
        // get the canvas element and its context
        const canvas = document.getElementById('sketchpad')
        const context = canvas.getContext('2d')
        context.lineWidth = 14
        context.lineCap = 'round'
        let isIdle = true

        function drawStart(event) {
          context.beginPath()
          context.moveTo(
            event.pageX - canvas.offsetLeft,
            event.pageY - canvas.offsetTop
          )
          isIdle = false
        }
        function drawMove(event) {
          if (isIdle) return
          context.lineTo(
            event.pageX - canvas.offsetLeft,
            event.pageY - canvas.offsetTop
          )
          context.stroke()
        }
        function drawEnd(event) {
          isIdle = true
          makePrediction(canvas)
        }
        function touchStart(event) {
          drawStart(event.touches[0])
        }
        function touchMove(event) {
          drawMove(event.touches[0])
          event.preventDefault()
        }
        function touchEnd(event) {
          drawEnd(event.changedTouches[0])
        }

        function clean() {
          context.fillStyle = '#fff'
          context.fillRect(0, 0, canvas.clientWidth, canvas.clientHeight)
          displayResults(new Array(10).fill(1))
        }

        canvas.addEventListener('touchstart', touchStart, false)
        canvas.addEventListener('touchmove', touchMove, false)
        canvas.addEventListener('touchend', touchEnd, false)

        canvas.addEventListener('mousedown', drawStart, false)
        canvas.addEventListener('mousemove', drawMove, false)
        canvas.addEventListener('mouseup', drawEnd, false)
        document.getElementById('clear').onclick = clean

        // Prep canvas
        clean()
      }

      function toggleVideo(e) {
        const backVid = document.getElementById('backgroundContainer')
        if (backVid.paused) {
          backVid.play()
        } else {
          backVid.pause()
        }
        return false
      }
    </script>
  </head>
  <body>
    <video autoplay muted loop id="backgroundContainer">
      <source src="universe.mp4" type="video/mp4" />
    </video>

    <h1>Transfer Learning - Warp Speed!</h1>
    <h2>Load and Train the AI</h2>
    <button id="load" onclick="loadLabeled()">Load Training Images</button>
    <button id="feature" onclick="createFeature()" disabled>
      Create Feature Model
    </button>
    <button id="transfer" onclick="createTransfer()" disabled>
      Create Transfer Model
    </button>
    <button id="train" onclick="train()" disabled>Train Model</button>

    <h2>Test the AI</h2>
    <div id="drawspace">
      <button style="display: flex" id="clear" disabled>Clear</button>
      <canvas
        id="sketchpad"
        onSelectStart="this.style.cursor='crosshair'; return false;"
        width="500"
        height="500"
        style="border: 1px solid #777"
        disabled
      />
    </div>
    <div class="results">
      <div class="result" id="starfleet">
        <img src="images/starfleet.png" class="logo" />
        Starfleet
      </div>
      <div class="result" id="klingon">
        <img src="images/klingon.png" class="logo" />
        Klingon
      </div>
      <div class="result" id="ferengi">
        <img src="images/ferengi.png" class="logo" />
        Ferengi
      </div>
    </div>
    <div id="footer">
      <a href="../">Go Back to AI Sorting Hat</a>
      <a href="#" onclick="toggleVideo()">Toggle Background Animation</a>
    </div>
  </body>
</html>
